{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:**\n",
    "- Part 3: give them reads and controls to run the pipeline themselves\n",
    "- Let them symlink krona/diamond databases \n",
    "- Check that everything works: change paths, etc.\n",
    "- Implement tmux, check runtime spades, diamond,..\n",
    "- Insert krona images as example\n",
    "- Make github repo with images and change relative paths to absolute paths\n",
    "- Final spelling/format checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"https://rega.kuleuven.be/cev/viralmetagenomics/pictures/lovm/image_preview\" height=\"10%\" width=\"10%\" />\n",
    "\n",
    "# JM-lab bioinformatics pipeline\n",
    "This jupyter notebook gives an overview of the commands needed for the primary analysis of raw NGS data, flavoured with explanations and neat tips and tricks. This is intended as a learning tool for new PhD-students, master students, interns, etc. Basic command-line knowledge is required to be able to complete this tutorial, a Linux introduction course like [this one](https://ryanstutorials.net/linuxtutorial/) should suffice.\n",
    "\n",
    "This tutorial can be followed by running the commands directly from the terminal or within this jupyter notebook. To run a jupyter notebook on the teaching server, copy it to the `~/data/jupyternotebooks/` folder and open an internet browser to navigate to [bmw.gbiomed.kuleuven.be](https://bmw.gbiomed.kuleuven.be/), log in with your KU Leuven credentials which should finally allow you to run the notebook. You can find more information on how to transfer files to a remote server [below](#1.2-Installing-an-SFTP-client).\n",
    "\n",
    "#### Requirements:\n",
    "\n",
    "* Internet connection\n",
    "* Basic Linux command-line knowledge\n",
    "* Local copy of the [Github repository](https://github.com/Matthijnssenslab) with this jupyter notebook, solutions notebook, extra solution files, etc.\n",
    "* NetoVIR FASTQ-files, custom DIAMOND and Krona databases from the J-drive\n",
    "* Bioinformatics mood\n",
    "\n",
    "#### Overview:\n",
    "\n",
    "* [Part 1: Preparation](#Part-1:-Preparation)\n",
    "* [Part 2: Pipeline](#Part-2:-Virome-pipeline)\n",
    "    * [Basic NGS commands](#Basic-commands-when-working-with-NGS-data)\n",
    "    * [Trimming and QC](#2.1-Trimming-and-QC)\n",
    "    * [Removing contamination](#2.2-Removing-contamination)\n",
    "    * [Assembly](#2.3-Assembly)\n",
    "    * [Taxonomical annotation](#2.4-Taxonomical-annotation)\n",
    "    * [Visualization with Krona](#2.5-Visualization-with-Krona)\n",
    "---\n",
    "## **Part 1: Preparation**\n",
    "### 1.1 Logging into the teaching server\n",
    "To be able to perform analysis on a Linux machine or a server, a connection needs to be made through the shell of the operating system. Through this shell we can use the command-line interface to execute tasks.\n",
    "\n",
    "For this tutorial we can work on the teaching server of gbiomed (bmw.gbiomed.kuleuven.be). Everyone with a u- or r-number from KU Leuven can connect to this remote server by using `ssh` ([more info](https://searchsecurity.techtarget.com/definition/Secure-Shell)) with your KU Leuven credentials.\n",
    "\n",
    "MacOS and Linux users can already proceed to the next step as these operating systems already have a terminal and `ssh` natively installed. \n",
    "\n",
    "Windows users on the other hand, will have to install an SSH client ([PuTTY](https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) or [Bitvise](https://www.bitvise.com/ssh-client-download)) or a Linux subsytem for Windows (the latter is preferred because it is already a part of Windows and subsequently the next steps will be the same as for Linux and Mac users). Instructions on how to install Ubuntu on Windows can be found [here](https://ubuntu.com/tutorials/ubuntu-on-windows#1-overview), be aware that this requires at least a x86 PC running Windows 10 (Fall Creators update Oct 2017).\n",
    "\n",
    "**Perform following actions in a terminal (command-line interface):**\n",
    "\n",
    "<span style=\"color:red\">Replace uXXXXXXX with your u- or r-number. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh uXXXXXXX@bmw.gbiomed.kuleuven.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you should give your password connected to your KU Leuven account and you're in!\n",
    "\n",
    "<b><span style=\"color:red\"> Important:</span> You will log in to the `home` directory, but always avoid working in here as this has limited storage and will cause trouble when it's full!</b> Therefore, on the teaching server, work in the `data` directory, which is a symbolic link to `/mnt/storage/uXXXXXXX`. Here, you will have enough space to store raw data, results and databases.\n",
    "\n",
    "### 1.2 Installing an SFTP client\n",
    "\n",
    "In order to transfer files from your local computer to a remote server you need an SFTP (SSH or Secure File Transfer Protocol) client, a commonly used SFTP client is [FileZilla](https://filezilla-project.org/). You can download and install it through the FileZilla project website.\n",
    "\n",
    "*Note: Bitvise is an SSH and SFTP client in one, so if you're using Bitvise there is no need to install FileZilla.*\n",
    "\n",
    "Once you installed and opened FileZilla, it should look like this:\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"images/Filezilla_start.png\" height=\"80%\" width=\"80%\" style=\"left\" /></center>\n",
    "\n",
    "On top of the program you can fill out the host (bmw.gbiomed.kuleuven.be), your u/r-number and password connected to KU Leuven and set the port to 22 (see image above). \n",
    "\n",
    "Once you click connect you should be able to transfer files from your computer to the remote server simply by dragging them one or the other way. \n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"images/Filezilla_transfer.png\" height=\"80%\" width=\"80%\" style=\"left\" /></center>\n",
    "\n",
    "<span style=\"color:red\"> Important:</span> FileZilla will connect to your `home` directory by default, but do not copy files here! Instead, copy them to the `data` directory.\n",
    "\n",
    "#### 1.2.1 Transfer files\n",
    "Make a new directory in your data folder and transfer all provided files (FASTQ, database, primer file, etc.) to this directory with FileZilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ~/data/meta_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Installing all necessary software on the remote server\n",
    "#### 1.3.1 Miniconda\n",
    "(Mini)conda is a package manager from which you can install a lot of (bioinformatics) software. More info on conda can be found [here](https://docs.conda.io/projects/conda/en/latest/).\n",
    "\n",
    "**Perform following steps to install all software we will need along the pipeline:**\n",
    "1. Create in your datafolder a new `software` directory and move into that directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/data\n",
    "mkdir software\n",
    "cd software\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the Miniconda installer with `wget`. Next, run the installation script (`-b` makes the installation run silent and `-p` provides the path where to install Miniconda). When Miniconda is installed, activate conda by sourcing the initialization script, this simply sets a couple of shell environment variables, and `conda` command as a shell function. More information in the [installer guidelines](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/data/software/miniconda\n",
    "source $HOME/data/software/miniconda/bin/activate\n",
    "conda init\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that* `$HOME` *and* `~/` *both point to your `home` directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. When installing new software with conda, the best practice is to create a new conda environment for each project you are working on, for example:\n",
    "\n",
    "In this tutorial we will run the virome pipeline, so we will create a conda environment with all software we need to run the pipeline installed in this environment. Then we need to activate this environment to make the software available for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -y --name virome_pipeline python\n",
    "conda activate virome_pipeline\n",
    "conda install -y -c bioconda -c anaconda krona samtools bwa-mem2 bowtie2 trimmomatic bedtools fastqc pigz seqtk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading taxonomy database for Krona\n",
    "Krona is installed but we still need to run `ktUpdateTaxonomy.sh` to download the taxonomy database, see message below:\n",
    "\n",
    "```console\n",
    "Krona installed.  You still need to manually update the taxonomy databases before Krona can generate taxonomic reports. The update script is ktUpdateTaxonomy.sh. \n",
    "The default location for storing taxonomic databases is /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "\n",
    "If you would like the taxonomic data stored elsewhere, simply replace\n",
    "this directory with a symlink.  For example:\n",
    "```\n",
    "```bash\n",
    "rm -rf /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "mkdir /path/on/big/disk/taxonomy\n",
    "ln -s /path/on/big/disk/taxonomy /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "ktUpdateTaxonomy.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktUpdateTaxonomy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 From another source\n",
    "\n",
    "The bioconda installation will most of the time lag a few versions behind the most current release. If you really want the most recent, then you'll need to manually install the software and its dependencies.\n",
    "\n",
    "Next to Anaconda/Miniconda their are a lot of other possibilities to install software (`pip`, compiling from source, unpacking binaries, installing from github repository, etc.)\n",
    "\n",
    "As the latest version of [DIAMOND](https://github.com/bbuchfink/diamond) (a sequence aligner for protein and translated DNA searches) is not available through `conda`, we can install it from github by following the [installation instructions](https://github.com/bbuchfink/diamond/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd ~/data/software/\n",
    "mkdir diamond\n",
    "cd diamond\n",
    "wget http://github.com/bbuchfink/diamond/releases/download/v2.0.6/diamond-linux64.tar.gz\n",
    "tar -xzf diamond-linux64.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still need to put the diamond executable in our `PATH` variable so we can call the `diamond` command from everywhere in the command line. This can be done by making a `bin` subdirectory in `~/data/software/`, followed by creating a symlink from the `diamond` executable to `~/data/software/bin/` and finally export this directory to our `$PATH` by adding it to your `.profile` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/data/software\n",
    "mkdir bin\n",
    "cd bin/\n",
    "ln -s ~/data/software/diamond/diamond ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, open the `.profile` file with `nano` (a text editor) and add following line to the bottom of the file:\n",
    "```bash\n",
    "PATH=\"~/data/software/bin:$PATH\"\n",
    "```\n",
    "More documentation on how and where to set the `PATH` variable in these two topics: \n",
    "* __How__: [How to correctly add a path to PATH](https://unix.stackexchange.com/questions/26047/how-to-correctly-add-a-path-to-path)\n",
    "* __Where__: [Difference between .bashrc and .profile files](https://superuser.com/questions/183870/difference-between-bashrc-and-bash-profile/183980#183980)\n",
    "\n",
    "\n",
    "\n",
    "When you `source` your `.profile` file, you should now be able to call `diamond`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ~/.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the version of Diamond you have installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diamond version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3-1 Exercise\n",
    "Try to install the latest version of [SPAdes](https://github.com/ablab/spades) by yourself. If you have troubles with this exercise, the steps are listed in the solutions notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Part 2: Virome pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, some commandments to live by:\n",
    "1. **Always make sure you're working in the right directory** (`pwd`) and that you **activated the `conda` environment** you need\n",
    "2. Try the `-h`, `-help` or `--help` documentation for more information about the pogram you're using.\n",
    "3. **<kbd>Ctrl</kbd> + <kbd>C</kbd>** kills tasks, useful when they get stuck \n",
    "4. Undoubtedly **errors will occur**, read them carefully and **try to understand what they want to tell you**. \n",
    "5. **Document what you're coding**: Use `#` in a shell script, code block, etc. This will allow you to leave comments in your code, as all lines with a `#` in front will not be interpreted.\n",
    "6. **Google is your friend!** Websites like Stackoverflow, Superuser, Biostars, etc. most likely contain the answers to your questions (if you can phrase them properly)\n",
    "\n",
    "### Basic commands when working with NGS data\n",
    "Commands to do some basic manipulations on sequence data are given below. These always come in handy when working with fasta/fastq files.\n",
    "1. Count how many reads are in a fastq.gz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat <fastq.gz> | echo $((`wc -l`/4)) #when you have an uncompressed fastq, replace zcat with cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Count how many sequences are in a fasta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep -c \"^>\" <fasta> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will count the occurrence of \"**>**\" signs that are at the beginning of a line (this is indicated by the \"**^**\"). Because each fasta header starts with a \">\", you will know how many sequences are in the fasta file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert fastq to fasta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtk seq -a <fastq> > <fasta> #seqtk has to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Subset specific fasta sequences from a multifasta file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtk subseq <multifasta> <list-fasta-header-id> #seqtk has to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Get the sequence length and nucleotide distribution in a fasta file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtk comp <fasta> #seqtk has to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1 Trimming and QC\n",
    "**Raw reads are imperfect** due to presence of primer and adapter sequences from WTA2, Nextera library prep,... and because NGS inherently produces some errors during base calling. The quality of such a base call gets encoded in a FASTQ file as a [PHRED-score](https://en.wikipedia.org/wiki/Phred_quality_score#:~:text=The%20FASTQ%20format%20encodes%20phred,efficacy%20of%20different%20sequencing%20methods.). This also means that the raw reads have to be filtered and trimmed for these imperfections. We can do this by using software (eg. Trimmomatic, cutadapt, etc.) that will trim the reads based on base call quality and the presence of adapter sequences provided by the user. However, also after trimming your reads, it is best to check the quality of you samples.\n",
    "\n",
    "#### 2.1.1 Trimmomatic\n",
    "We start by trimming the reads in our sample with Trimmomatic, a flexible read trimming tool for Illumina NGS data.\n",
    "\n",
    "The current Trimmomatic trimming steps are:\n",
    "\n",
    "- **ILLUMINACLIP**:<i>\\<fastaWithAdaptersEtc>:\\<seed mismatches>:\\<palindrome clip>:\\<simple clip threshold> </i><br /> Cut adapter and other illumina-specific sequences from the read. You can provide a file with all sequences to cut (for this tutorial we use *primer_WTA2_Nextera.fa*).\n",
    "- **SLIDINGWINDOW**:<i>\\<windowSize>:\\<requiredQuality> </i><br />Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold. By considering multiple bases, a single poor quality base will not cause the removal of high quality data later in the read. \n",
    "- **LEADING**:<i>\\<quality> </i> <br />Cut bases off the start of a read, if below a threshold quality\n",
    "- **TRAILING**:<i>\\<quality> </i> <br />Cut bases off the end of a read, if below a threshold quality\n",
    "- **CROP**:<i>\\<length> </i> <br />Cut the read to a specified length *(not used in our pipeline)*\n",
    "- **HEADCROP**:<i>\\<length> </i> <br />Cut the specified number of bases from the start of the read\n",
    "- **MINLEN**:<i>\\<length> </i> <br />Drop the read if it is below a specified length\n",
    "\n",
    "It works with FASTQ, either uncompressed or gzipp'ed FASTQ. Use of gzip format is determined based on the .gz extension.\n",
    "\n",
    "For single-ended data, one input and one output file are specified, plus the processing steps. For paired-end data, two input files are specified, and 4 output files, 2 for the 'paired' output where both reads survived the processing, and 2 for corresponding 'unpaired' output where a read survived, but the partner read did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to the directory where you stored the tutorial files\n",
    "cd ~/data/meta_tutorial\n",
    "pwd #make sure you're in the right directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make new folders where you will store the data for each individual metatoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir metatoy\n",
    "cd metatoy\n",
    "mkdir READ\n",
    "mv ../metatoy.R* ./READ\n",
    "cd ./READ\n",
    "mkdir TRIMMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After unzipping the FASTQ files, start Trimmomatic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd #your working directory should be ~/data/meta_tutorial/metatoy/READ/ if you used the same names as in this notebook\n",
    "\n",
    "pigz -d -p 20 -c metatoy.R1.fastq.gz > metatoy.R1.fastq\n",
    "pigz -d -p 20 -c metatoy.R2.fastq.gz > metatoy.R2.fastq\n",
    "\n",
    "#PE stands for Paired-end, for single-end reads use SE\n",
    "trimmomatic PE -threads 20 metatoy.R1.fastq metatoy.R2.fastq \\ #the backslash (\\) allows us to let the command continue over multiple lines\n",
    "                TRIMMED/metatoy.R1.trimmed.fastq TRIMMED/metatoy.R1.unpaired.fastq TRIMMED/metatoy.R2.trimmed.fastq \\\n",
    "                TRIMMED/metatoy.R2.unpaired.fastq \\\n",
    "                ILLUMINACLIP:~/data/meta_tutorial/primer_WTA2_Nextera.fa:2:30:10:1:true \\\n",
    "                HEADCROP:19 LEADING:15 TRAILING:15 SLIDINGWINDOW:4:20 MINLEN:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Try to understand what all specified options do in the Trimmomatic command. <br>Hint: Remember the 6th commandment.*\n",
    "\n",
    "<details style=\"cursor:pointer\" >\n",
    "    <summary>Solutions for the Trimmomatic options </summary>\n",
    "    More info in the <a href=\"http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf\">manual</a>\n",
    "    <br>\n",
    "    <hl><b> ILLUMINACLIP: </b></hl>\n",
    "        <li><code>~/data/meta_tutorial/primer_WTA2_Nextera.fa</code>: provides the path to the fasta file with adapter and primer sequences </li>\n",
    "        <li><code>2</code>: represents the number of max mismatches allowed to still perform a full match with an adapter sequence</li>\n",
    "        <li><code>30</code>: specifies how accurate the match between the two 'adapter ligated' reads must be for PE palindrome read alignment</li>\n",
    "        <li><code>10</code>: specifies how accurate the match between any adapter sequence must be against a read.</li>\n",
    "        <li><code>1</code>: a minimal adapter length of 1 allows for shorter adapter fragments to be removed </li>\n",
    "        <li><code>true</code>: retain the reverse read</li>\n",
    "    <br>\n",
    "    <hl><b>HEADCROP:</b></hl>\n",
    "    <li><code>19</code>: remove the first 19 bases of the read</li>\n",
    "    <br>\n",
    "    <hl><b>LEADING:</b></hl>\n",
    "    <li><code>15</code>: bases at the beginning of the read with a PHRED-score below 15 will be removed</li>\n",
    "    <br>\n",
    "    <hl><b>TRAILING:</b></hl>\n",
    "    <li><code>15</code>: bases at the end of the read with a PHRED-score below 15 will be removed</li>\n",
    "    <br>\n",
    "    <hl><b>SLIDINGWINDOW:</b></hl>\n",
    "    <li><code>4</code>: determines the window size at 4bp to slide over the read</li>\n",
    "    <li><code>20</code>: once the average quality in the window falls below 20, trimmomatic will cut the read</li>\n",
    "    <br>\n",
    "    <hl><b>MINLEN:</b></hl>\n",
    "    <li><code>50</code>: drop reads shorter than 50bp</li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Concatenate the unpaired reads together and in order to save storage space, remove all intermediary files and gzip the trimmed fastq files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat TRIMMED/metatoy.R1.unpaired.fastq TRIMMED/metatoy.R2.unpaired.fastq > TRIMMED/metatoy.unpaired.fastq\n",
    "rm TRIMMED/metatoy.R1.unpaired.fastq\n",
    "rm TRIMMED/metatoy.R2.unpaired.fastq\n",
    "cd TRIMMED\n",
    "\n",
    "pigz -p 20 -c -9 metatoy.R1.trimmed.fastq > metatoy.R1.trimmed.fastq.gz\n",
    "pigz -p 20 -c -9 metatoy.R2.trimmed.fastq > metatoy.R2.trimmed.fastq.gz\n",
    "pigz -p 20 -c -9 metatoy.unpaired.fastq > metatoy.unpaired.trimmed.fastq.gz\n",
    "\n",
    "rm metatoy.R1.trimmed.fastq\n",
    "rm metatoy.R2.trimmed.fastq\n",
    "rm metatoy.unpaired.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 FastQC\n",
    "Most sequencers will generate a QC report as part of their analysis pipeline, but this is usually only focused on identifying problems which were generated by the sequencer itself. FastQC aims to provide a QC report which can spot problems which originate either in the sequencer or in the starting library material.\n",
    "\n",
    "FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It is very useful software to visually inspect the quality of samples and runs for most of the current sequencing platforms (Illumina, IonTorrent, Nanopore, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/data/meta_tutorial/metatoy\n",
    "mkdir fastqc\n",
    "fastqc -o fastqc/ -t 6 READ/TRIMMED/*.fastq.gz #the wildcard '*' is used to run `fastqc` on all FASTQ files within the 'TRIMMED' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the generated HTML-files and look if your sample passes QC. In the `fastqc` folder of the tutorial's repository, you can find the FastQC-files of the reads **before** and **after** trimming (the latter should be the same as your own). Have a look at them and pay attention to the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Removing contamination\n",
    "When working in the lab it is likely that you introduce contamination to your samples, for example because the reagents are contaminated. That's why we also sequence some negative controls. By *de novo* assembling your negative controls first, you can create a **contaminome**. Subsequently, you can remove all reads in your samples that map to this contaminome.\n",
    "\n",
    "#### 2.2.1 Mapping\n",
    "Mapping is a **specific case of alignment** for aligning short sequences (reads) to a reference. This is performed by a short sequence aligner/mapper (eg. Bowtie, BWA, etc.). In this case, we align sequencing reads to the assembled contaminome sequences. The output of the mapping process is stored in **SAM-files** (Sequence Alignment Map) or their compressed equivalent **BAM** (Binary Alignment Map).\n",
    "\n",
    "In the image below a visual representation is given on the mapping of reads to a reference sequence:\n",
    "<br>\n",
    "<center><img src=\"https://training.galaxyproject.org/training-material/topics/sequence-analysis/images/mapping/mapping.png\" width=\"50%\" heiht=\"50%\" style=\"border: 1px solid black\"/></center>\n",
    "<center><b>Overview of read mapping to a reference sequence</b></center>\n",
    "<br>\n",
    "\n",
    "We will use `bowtie2` to map the reads in our sample to the contaminome. To calculate the statistics of the mapping and remove the mapped reads from our sample, we can use `samtools` and `bedtools`. <br />\n",
    "In this tutorial, the contaminome is already assembled and indexed with `bowtie2`. You can find the files in the contaminome folder.\n",
    "\n",
    "##### Bowtie\n",
    "<a href=\"http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#introduction\">Bowtie2</a> is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences.\n",
    "\n",
    "Options:\n",
    "* `-x` should point to the indexed reference sequence\n",
    "* `--very-sensitive` aligns the reads on a sensitive setting at the cost of speed\n",
    "* `-p` causes Bowtie2 to launch a specified number of parallel search threads\n",
    "* `-S` specifies the output SAM file\n",
    "* `-1` and `-2` should provide the input read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/data/meta_tutorial/metatoy/READ/TRIMMED\n",
    "bowtie2 --very-sensitive -p 20 -x ~/data/meta_tutorial/contaminome/contaminome -1 metatoy.R1.trimmed.fastq.gz -2 metatoy.R2.trimmed.fastq.gz -S mapunmap_pair.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Removing mapped reads\n",
    "##### Samtools\n",
    "<a href=\"http://www.htslib.org/\">Samtools</a> is a set of utilities that manipulate alignments in the SAM/BAM format. It imports from and exports to the SAM format, does sorting, merging and indexing, and allows to retrieve reads in any regions swiftly.\n",
    "\n",
    "An important function of `samtools` is the ability to keep or remove certain reads by specifying **SAM flags**. Reads are assigned a certain SAM flag, this number represents a certain combination of features of the alignment. Actually, the flag field consists of 10 bits, of which every bit is related to the abscence (0) or presence (1) of a feature. So while the features are stored in bitwise fashion, to report this number, the FLAG field converts these bits to a readable number, the number these bits represent. Unfortunately, this is number is still very user-unfriendly to read. Luckily, there are tools to convert this number into a feature list, like [this one](https://broadinstitute.github.io/picard/explain-flags.html).\n",
    "<br>\n",
    "\n",
    "**Different features of the reads:**\n",
    "\n",
    "<table align=\"left\">\n",
    "<thead>\n",
    "    <tr>\n",
    "        <th align=\"left\">Feature</th>\n",
    "        <th align=\"left\">SAM Flag</th>\n",
    "    </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "    <tr>\n",
    "        <td align=\"left\">read paired</td>\n",
    "        <td align=\"right\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">all mate reads are mapped</td>\n",
    "        <td align=\"right\">2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">read unmapped</td>\n",
    "        <td align=\"right\">4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">mate unmapped</td>\n",
    "        <td align=\"right\">8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">read reverse strand</td>\n",
    "        <td align=\"right\">16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">mate reverse strand</td>\n",
    "        <td align=\"right\">32</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">first read of pair</td>\n",
    "        <td align=\"right\">64</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">second read of pair</td>\n",
    "        <td align=\"right\">128</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">secondary alignment</td>\n",
    "        <td align=\"right\">256</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">read fails quality checks</td>\n",
    "        <td align=\"right\">512</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">read is PCR or optical duplicate</td>\n",
    "        <td align=\"right\">1024</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\">supplementary alignment</td>\n",
    "        <td align=\"right\">2048</td>\n",
    "    </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some examples:**\n",
    "\n",
    "1. <span style=\"color:green\"><b>Flag 16</b></span> indicates a <b>read on the reverse strand</b>. <br />\n",
    "   **To exclude** all reads on the reverse strand we can use the `-F` option of `samtools`, `-f` on the other hand would **only include** reads on the reverse strand.\n",
    "\n",
    "2. By combining flags, multiple combinations of features can be made, eg. <span style=\"color:green\"><b>Flag 68</b></span> indicates that this read is the <b>first read of the pair (<span style=\"color:green\">flag 64</span>) and that it is unmapped (<span style=\"color:green\">flag 4</span>)</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools view -bS mapunmap_pair.sam | samtools view -b -f12 -F256 - | samtools sort -n - -o PEunmapped.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try to figure out what `-f12` and `-F256` mean and think about why we would use these options?\n",
    "<details style=\"cursor:pointer\">\n",
    "    <summary>Solution</summary>\n",
    "    <li><span style=\"color:green\"><b>Flag 12</b></span> specifies all <b>unmapped reads and their mate</b>, we keep these by specifying the <code>-f</code> option.</li>\n",
    "    <li><span style=\"color:green\"><b>Flag 256</b></span> indicates a <b>secondary alignment</b>, this occurs when a given read could align reasonably well to more than one place. <code>-F</code> excludes all those reads.</li> <br>\n",
    "    We use these specified options, because we like to exclude all reads that (ambiguously) map to our contaminome.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bedtools\n",
    "In the end, we want to convert the resulting BAM file back to a FASTQ file, which can be handled by Bedtools' `bamToFastq`. <br>\n",
    "`pigz` handles the compressing of the files to reduce required storage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamToFastq -i PEunmapped.sorted.bam -fq NCout.R1.fastq -fq2 NCout.R2.fastq\n",
    "rm mapunmap_pair.sam\n",
    "rm PEunmapped.sorted.bam\n",
    "pigz -p 20 -c -9 NCout.R1.fastq > metatoy.NCout.R1.fastq.gz\n",
    "pigz -p 20 -c -9 NCout.R2.fastq > metatoy.NCout.R2.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2-1\n",
    "For the unpaired reads we can do the same as above, try to fill in the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowtie2 ... -U ... #-U is the input for unpaired reads\n",
    "samtools view ... | samtools view ... | samtools sort ...\n",
    "bamToFastq ...\n",
    "rm ...\n",
    "rm ...\n",
    "pigz ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all uncompressed FASTQ files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm NCout.*.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 Assembly\n",
    "Now that we have our contaminant-filtered and trimmed reads, we have to reconstruct the genomes to which they belong. We can do this by **assembling** all reads into **contigs** (contiguous sequence) and finally into **scaffolds**. The goal of whole-genome shotgun assembly is to represent each genomic sequence in one scaffold; however, this is not always possible. It depends on how completely the genome can be reconstructed, or assembled, from the available reads.\n",
    "\n",
    "There are two types of assemblies: \n",
    "1. a __reference-guided assembly__: Your reads will get assembled based on a reference sequence you provide. This is used when you know what you are sequencing.\n",
    "2. a __*de novo* assembly__: This method constructs genomes from a large number of (short- or long-) DNA fragments, with no *a priori* knowledge of the correct sequence or order of those fragments (see images below).\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "    <td> <img src=\"https://www.arraygen.com/images/de-novo.png\" style=\"margin-left:75px\"/> </td>\n",
    "    <td>\n",
    "         <img src=\"images/PE_scaffolds.jpg\" width=\"70%\" height=\"70%\" style=\"float:right;margin-right:75px\" />\n",
    "    </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: white\">\n",
    "        <td align=\"center\"> <b><i>de novo</i> assembly</b> </td>\n",
    "        <td align=\"right\" style=\"float:right;margin-right:10px\"> <b>The gaps in a scaffold can be estimated because the paired-end reads may overlap multiple contigs</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "We will use [(meta)SPAdes](https://cab.spbu.ru/software/spades/) to *de novo* assemble our reads, because it has proven to be a very robust assembler of metagenomic data. SPAdes uses a range of k-mers with different sizes for building an initial *de Bruijn graph* and on following stages it performs graph-theoretical operations which are based on graph structure, coverage and sequence lengths. Moreover, it adjusts errors iteratively. [This video](https://www.youtube.com/watch?v=TNYZZKrjCSk) explains what a *de Bruijn graph* is and why it is superior to *overlap graphs* for handling repetitive regions in a sequence.  \n",
    "\n",
    "The stages of assembly in SPAdes are:\n",
    "\n",
    "Stage 1: assembly graph construction. SPAdes employs multisized *de Bruijn graphs*, which detect and remove bulge/bubble (errors in the middle of a read) and chimeric reads.  \n",
    "Stage 2: k-bimer (pairs of k-mers) adjustment. Exact distances between k-mers in the genome (edges in the assembly graph) are estimated.  \n",
    "Stage 3: paired assembly graph construction.  \n",
    "Stage 4: contig construction. SPAdes outputs contigs and allows to map reads back to their positions in the assembly graph after graph simplification (backtracking).  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaspades.py -1 ./READ/TRIMMED/metatoy.NCout.R1.fastq.gz -2 ./READ/TRIMMED/metatoy.NCout.R2.fastq.gz -s ./READ/TRIMMED/metatoy.NCout.unpaired.fastq.gz -t 20 -k 21,33,55,77 -o metatoy\n",
    "mv metatoy ASSEMBLY\n",
    "cd ASSEMBLY\n",
    "mv scaffolds.fasta metatoy.scaffolds.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`metaspades.py` options:\n",
    "* `-1`, `-2` and `-s` point to the read files\n",
    "* `-t` specifies how much threads to use (basically how many parallel tasks the cpu may perform, this can speed up a program tremendously)\n",
    "* `-k` indicates the k-mer sizes to use to build the *de Bruijn graphs*. All values must be odd, less than 128 and listed in ascending order.\n",
    "* `-o` output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SPAdes output\n",
    "SPAdes outputs a `contigs.fasta` file and a `scaffolds.fasta` file, we will use the scaffolds FASTA further in this pipeline. To add the sample name in the header of each scaffold, we use `sed` which can handle basic text transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add the sample names to your assemblies\n",
    "sed -i \"s/>.*/&_metatoy/\" metatoy.scaffolds.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `-i` to edit a file in-place instead of printing to standard output  \n",
    "* `\"s/>.*/&_metatoy/\"`   \n",
    "There are four parts to a substitute command:\n",
    "```bash\n",
    "\"s/ONE/one/\"\n",
    "s\t    Substitute command\n",
    "/../../  Delimiter\n",
    "ONE\t  Regular Expression Search Pattern\n",
    "one\t  Replacement string\n",
    "```  \n",
    "\n",
    "Here we use `>.*` to find all lines that start with '>' (fasta header) and use the `&` symbol to append '_metatoy' to the header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.4 Taxonomical annotation\n",
    "Sequences or after assembly, contigs or scaffolds, can be identified based on similarity with known sequences in databases. **Similarity can be measured by k-mer profile matching** (eg. Kraken2),  **fitness to a model** (eg. fitness to a hidden Markov-model with HMMER) **or similarity in alignments**. There are many programs and implementations for each, but one of the best known is [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi) which finds regions of similarity in sequences by alignment.\n",
    "\n",
    "**From Blast, there are several options to query information:**\n",
    "\n",
    "<table align =\"left\">\n",
    "    <thead>\n",
    "    <tr>\n",
    "    <th style=\"text-align:left\">BLAST</th>\n",
    "    <th style=\"text-align:left\">Query</th>\n",
    "    <th style=\"text-align:left\">Subject</th>\n",
    "    <th style=\"text-align:center\">DIAMOND</th>\n",
    "    </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">blastn</td>\n",
    "    <td style=\"text-align:left\">nucleotide</td>\n",
    "    <td style=\"text-align:left\">nucleotide</td>\n",
    "    <td style=\"text-align:center\">&cross;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">blastp</td>\n",
    "    <td style=\"text-align:left\">protein</td>\n",
    "    <td style=\"text-align:left\">protein</td>\n",
    "    <td style=\"text-align:center\">&check;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">tblastn</td>\n",
    "    <td style=\"text-align:left\">protein</td>\n",
    "    <td style=\"text-align:left\">translated-nucleotide</td>\n",
    "    <td style=\"text-align:center\">&cross;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">blastx</td>\n",
    "    <td style=\"text-align:left\">translated-nucleotide</td>\n",
    "    <td style=\"text-align:left\">protein</td>\n",
    "    <td style=\"text-align:center\">&check;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">tblastx</td>\n",
    "    <td style=\"text-align:left\">translated-nucleotide</td>\n",
    "    <td style=\"text-align:left\">translated-nucleotide</td>\n",
    "    <td style=\"text-align:center\">&cross;</td>\n",
    "    </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "<br clear=\"left\" />\n",
    "\n",
    "*Be aware that all nucleotide translations occur in 6-frames.*\n",
    "\n",
    "When querying a large database like the non-redundant protein database of NCBI (nr), it can take a long time for BLAST to finish the search. This is why we will use **DIAMOND**.\n",
    "\n",
    "#### 2.4.1 DIAMOND\n",
    "\n",
    "[DIAMOND](https://www.nature.com/articles/nmeth.3176) is a sequence aligner for protein and translated DNA searches, designed for high performance analysis of big sequence data. An important feature is its speed, it is able to align sequences 100 up to 20,000 times faster than BLAST with a similar degree of sensitivity. DIAMOND can only perform a pairwise-alignment of protein and translated-nucleotide sequences (see table above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir DIAMOND\n",
    "cd DIAMOND\n",
    "\n",
    "diamond blastx -d /staging/leuven/stg_00029/DB/nr/latest/nr.dmnd -q ../ASSEMBLY/metatoy.scaffolds.fasta -a metatoy -p 32 --sensitive -c 1 --tmpdir /dev/shm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`diamond blastx` creates a DIAMOND Alignment Archive (DAA) which can be formatted to a tabular output with `diamond view`.\n",
    "* `-d` points to the database to query\n",
    "* `-q` points to our scaffolds file with sequences for which we want to know the annotation\n",
    "* `-a` specifies the filename of the DAA\n",
    "* `-p` specifies how much threads to use\n",
    "* the `--sensitive` option enables the sensitive mode designed for full sensitivity for hits >40% identity\n",
    "* `-c` is the number of indexed chunks, setting this parameter to 1 will improve the performance at the cost of increased memory use\n",
    "* `--tmpdir` specifies the directory where to store temporary files, the `/dev/shm` directory keeps these files in the working memory while running DIAMOND but does not take up storage space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond view -d /staging/leuven/stg_00029/DB/nr/latest/nr.dmnd -a metatoy -o metatoy.m8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.m8` file shows the best 25 hits of DIAMOND for each scaffold in a tabular format.\n",
    "\n",
    "##### Header of the DIAMOND output file:\n",
    "\n",
    "<table align=\"left\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><strong>Query ID</strong></td>\n",
    "<td>Name of query sequence</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Subject ID</strong></td>\n",
    "<td>Accesion number of subject sequence</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>% Identity</strong></td>\n",
    "<td>percentage of identical matches</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>length</strong></td>\n",
    "<td>alignment length (sequence overlap)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>mismatch</strong></td>\n",
    "<td>number of mismatches</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>gapopen</strong></td>\n",
    "<td>number of gap openings</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>qstart</strong></td>\n",
    "<td>start of alignment in query</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>qend</strong></td>\n",
    "<td>end of alignment in query</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>sstart</strong></td>\n",
    "<td>start of alignment in subject</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>send</strong></td>\n",
    "<td>end of alignment in subject</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>evalue</strong></td>\n",
    "<td>expect value</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>bitscore</strong></td>\n",
    "<td>bit score</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of output file:\n",
    "<table align=\"left\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th style=\"text-align:left\">Scaffold name (query ID)</th>\n",
    "<th style=\"text-align:left\">Accession nr. (subject ID)</th>\n",
    "<th style=\"text-align:right\">% Identity</th>\n",
    "<th style=\"text-align:right\">length</th>\n",
    "<th style=\"text-align:right\">mismatches</th>\n",
    "<th style=\"text-align:right\">gap openings</th>\n",
    "<th>qstart</th>\n",
    "<th>qend</th>\n",
    "<th style=\"text-align:right\">sstart</th>\n",
    "<th>send</th>\n",
    "<th style=\"text-align:right\">e-value</th>\n",
    "<th style=\"text-align:right\">bitscore</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">...</td>\n",
    "<td style=\"text-align:left\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_1_length_152443_cov_1166.465412_metatoy</td>\n",
    "<td style=\"text-align:left\">YP_009617752.1</td>\n",
    "<td style=\"text-align:right\">84.1</td>\n",
    "<td style=\"text-align:right\">1612</td>\n",
    "<td style=\"text-align:right\">256</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>94773</td>\n",
    "<td>89938</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td>1612</td>\n",
    "<td style=\"text-align:right\">0.0e+00</td>\n",
    "<td style=\"text-align:right\">2726.8</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_1_length_152443_cov_1166.465412_metatoy</td>\n",
    "<td style=\"text-align:left\">YP_009887717.1</td>\n",
    "<td style=\"text-align:right\">84.1</td>\n",
    "<td style=\"text-align:right\">1612</td>\n",
    "<td style=\"text-align:right\">257</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>94773</td>\n",
    "<td>89938</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td>1612</td>\n",
    "<td style=\"text-align:right\">0.0e+00</td>\n",
    "<td style=\"text-align:right\">2725.7</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_1_length_152443_cov_1166.465412_metatoy</td>\n",
    "<td style=\"text-align:left\">YP_008771660.1</td>\n",
    "<td style=\"text-align:right\">84.0</td>\n",
    "<td style=\"text-align:right\">1612</td>\n",
    "<td style=\"text-align:right\">258</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>94773</td>\n",
    "<td>89938</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td>1612</td>\n",
    "<td style=\"text-align:right\">0.0e+00</td>\n",
    "<td style=\"text-align:right\">2725.3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_1_length_152443_cov_1166.465412_metatoy</td>\n",
    "<td style=\"text-align:left\">AYJ73679.1</td>\n",
    "<td style=\"text-align:right\">83.9</td>\n",
    "<td style=\"text-align:right\">1612</td>\n",
    "<td style=\"text-align:right\">259</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>94773</td>\n",
    "<td>89938</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td>1612</td>\n",
    "<td style=\"text-align:right\">0.0e+00</td>\n",
    "<td style=\"text-align:right\">2723.7</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_1_length_152443_cov_1166.465412_metatoy</td>\n",
    "<td style=\"text-align:left\">EGJ6623213.1</td>\n",
    "<td style=\"text-align:right\">83.9</td>\n",
    "<td style=\"text-align:right\">1612</td>\n",
    "<td style=\"text-align:right\">260</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>94773</td>\n",
    "<td>89938</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td>1612</td>\n",
    "<td style=\"text-align:right\">0.0e+00</td>\n",
    "<td style=\"text-align:right\">2723.7</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_2_length_31607_cov_0.550460_metatoy</td>\n",
    "<td style=\"text-align:left\">PHU22553.1</td>\n",
    "<td style=\"text-align:right\">99.5</td>\n",
    "<td style=\"text-align:right\">425</td>\n",
    "<td style=\"text-align:right\">2</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>31607</td>\n",
    "<td>30333</td>\n",
    "<td style=\"text-align:right\">41</td>\n",
    "<td>465</td>\n",
    "<td style=\"text-align:right\">8.9e-289</td>\n",
    "<td style=\"text-align:right\">890.2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_2_length_31607_cov_0.550460_metatoy</td>\n",
    "<td style=\"text-align:left\">PHT25532.1</td>\n",
    "<td style=\"text-align:right\">99.5</td>\n",
    "<td style=\"text-align:right\">425</td>\n",
    "<td style=\"text-align:right\">2</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>31607</td>\n",
    "<td>30333</td>\n",
    "<td style=\"text-align:right\">41</td>\n",
    "<td>465</td>\n",
    "<td style=\"text-align:right\">3.4e-288</td>\n",
    "<td style=\"text-align:right\">890.2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_2_length_31607_cov_0.550460_metatoy</td>\n",
    "<td style=\"text-align:left\">YP_008563087.1</td>\n",
    "<td style=\"text-align:right\">100.0</td>\n",
    "<td style=\"text-align:right\">425</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>31607</td>\n",
    "<td>30333</td>\n",
    "<td style=\"text-align:right\">41</td>\n",
    "<td>465</td>\n",
    "<td style=\"text-align:right\">1.9e-286</td>\n",
    "<td style=\"text-align:right\">892.5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">NODE_2_length_31607_cov_0.550460_metatoy</td>\n",
    "<td style=\"text-align:left\">YP_009171781.1</td>\n",
    "<td style=\"text-align:right\">99.8</td>\n",
    "<td style=\"text-align:right\">425</td>\n",
    "<td style=\"text-align:right\">1</td>\n",
    "<td style=\"text-align:right\">0</td>\n",
    "<td>31607</td>\n",
    "<td>30333</td>\n",
    "<td style=\"text-align:right\">41</td>\n",
    "<td>465</td>\n",
    "<td style=\"text-align:right\">4.8e-286</td>\n",
    "<td style=\"text-align:right\">891.3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">...</td>\n",
    "<td style=\"text-align:left\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "<td></td>\n",
    "<td style=\"text-align:right\"></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<br clear=\"left\"/>\n",
    "\n",
    "An important measurement of the appropriateness of the alignment is the **e-value**. The e-value or *expect value* is the probability of observing such results by chance. For instance, if you compare two identical sequences using BLAST/DIAMOND, it will return a value near 0, because having two identical sequences (without knowing they are the same) is quite improbable. Thus, a lower e-value indicates a better quality in the search/alignment/comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5 Visualization with Krona\n",
    "Now that we have our assembled scaffolds which are annotated by DIAMOND, it is possible to have an overall quantitative visualization that will help us to better understand the composition of the sample. [KronaTools](https://github.com/marbl/Krona/wiki) is a very nice tool to do this as it allows hierarchical data to be explored with zooming, multi-layered pie charts. \n",
    "<br>  \n",
    "**KronaTools will classify each scaffold into an OTU** (operational taxonomic unit), based on the lowest common ancestor of the 25 best DIAMOND hits (see [above](#2.4.1-DIAMOND)). Next, it will bundle the scaffolds that belong to the same OTU (eg. same virus, bacteria, eukaryote) and display this OTU's taxonomic ranks (kingdom, phylum, class, order, family, genus, species) in a pie chart.\n",
    "\n",
    "#### 2.5.1 Mapping with BWA\n",
    "In order to also let Krona show the abundance of an OTU in our sample, we have to **summarize how many reads map back to our assembled scaffolds**. We will do this with `bwa-mem2` which is, just like [bowtie2](#Bowtie), a read mapper. Both do the same job, but in general we can say that `bwa-mem2` is faster.\n",
    "\n",
    "1. The first step is to **index our scaffolds**. Indexing helps the mapping algorithms to work faster. It is like creating a dictionary of where in the 'genome' to find a particular sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwa-mem2 index metatoy.scaffolds.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, we **map the reads back to the scaffolds** and make a sorted BAM file with the paired and unpaired reads. Finally, we can merge two sorted BAM files into one which will contain all results of the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwa-mem2 mem metatoy.scaffolds.fasta ../READ/TRIMMED/metatoy.NCout.R1.fastq.gz ../READ/TRIMMED/metatoy.NCout.R2.fastq.gz -t 32 | samtools view -Su - | samtools sort - -o metatoy.R.sort.bam\n",
    "bwa-mem2 mem metatoy.scaffolds.fasta ../READ/TRIMMED/metatoy.NCout.unpaired.fastq.gz -t 32 | samtools view -Su - | samtools sort - -o metatoy.un.sort.bam\n",
    "samtools merge -f metatoy.bam metatoy.R.sort.bam metatoy.un.sort.bam\n",
    "rm metatoy.R.sort.bam\n",
    "rm metatoy.un.sort.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We index our BAM file and **report the summary statistics** with `samtools idxstats`. The output is tab-delimited with each line consisting of the sequence name, sequence length, # mapped read-segments and # unmapped read-segments. We subsequently cut the first and third column (sequence name and # mapped reads) from this output and paste it into a 'magnitudes' file. This file thus contains for each scaffold how many reads map to it. \n",
    "*Note: this may count reads multiple times if they are mapped more than once or in multiple fragments.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools index metatoy.bam\n",
    "samtools idxstats metatoy.bam | cut -f1,3 > metatoy.magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Visualization\n",
    "We installed KronaTools and the necessary databases in [Part 1](#Part-1:-Preparation) of this tutorial. We can now use it to build a pie chart which will contain information as: \n",
    "* the classification of each scaffold bundled in an OTU\n",
    "* OTU abundance in the sample, \n",
    "* average log<sub>10</sub> e-value for each OTU, \n",
    "* links to the [Taxonomy browser](https://www.ncbi.nlm.nih.gov/taxonomy), \n",
    "* etc.\n",
    "\n",
    "The input we have to give `ktImportBLAST` is our `m8` file with the output of DIAMOND and optionally our magnitudes file. The command is build like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktImportBLAST -o <output> <blast_output_1>:<magnitudes_file_1,<name_in_kronachart1> <blast_output_2>:<magnitudes_file_2,<name_in_kronachart2> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following command will give us two pie charts in the same html output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktImportBLAST -o metatoy.html metatoy.m8,metatoy metatoy.m8:metatoy.magnitudes,metatoy.magn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `metatoy.m8,metatoy`: A pie chart of OTU's without taking into account the magnitudes\n",
    "2. `metatoy.m8:metatoy.magnitudes,metatoy.magn`: Pie chart which proportionally shows how many reads map back to each OTU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Output classification\n",
    "We can output the classification of each scaffold into a file with `ktClassifyBLAST` of the KronaTools package. Together with the magnitudes, this will allows later on to make abundance and taxonomy tables for further analysis.\n",
    "\n",
    "The next command will output a tab-delimited file with the scaffold name, taxid and the e-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktClassifyBLAST metatoy.m8 -o metatoy.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some `awk` <span style=\"font-weight:bold;color:#ff00ff\">w</span><span style=\"font-weight:bold;color:#ff00cc\">i</span><span style=\"font-weight:bold;color:#ff0099\">t</span><span style=\"font-weight:bold;color:#ff0066\">c</span><span style=\"font-weight:bold;color:#ff0033\">h</span><span style=\"font-weight:bold;color:#ff0000\">c</span><span style=\"font-weight:bold;color:#ff3300\">r</span><span style=\"font-weight:bold;color:#ff6600\">a</span><span style=\"font-weight:bold;color:#ff9900\">f</span><span style=\"font-weight:bold;color:#ffcc00\">t</span>, we can print the magnitudes for each scaffold to the '.tab' file with the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk 'NR==FNR { a[$1]=$2; next} $1 in a {print $0,\"\\t\"a[$1]}' metatoy.magnitudes metatoy.tab > metatoy.magnitudes.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details style=\"cursor:pointer\">\n",
    "    <summary>Attempt to explain <code>awk</code> line</summary>\n",
    "    \n",
    "By default, <code>awk</code> considers a field to be a string of characters surrounded by whitespace, the start of a line or the end of a line. Fields are identified by a dollar sign (\\\\$) and a number. So, `$1` represents the first field of a file, `$2` the second field and so on. `$0` represents the whole line.\n",
    "\n",
    "1. <code>awk 'NR == FNR { # some actions; next} # other condition {# other actions}' file1.txt file2.txt</code><br>\n",
    "    When processing more than one file, awk reads each file sequentially, one after another, in the order they are specified on the command line. The special variable <b>NR</b> stores the total number of input records read so far, regardless of how many files have been read. The value of NR starts at 1 and always increases until the program terminates. Another variable, <b>FNR</b>, stores the number of records read <i>from the current file being processed</i>. The value of FNR starts at 1, increases until the end of the current file is reached, then is set again to 1 as soon as the first line of the next file is read, and so on. So, the condition <code>NR == FNR</code> is only true while awk is reading the first file. Thus, in the program above, the actions indicated by <b># some actions</b> are executed when awk is reading the first file; the actions indicated by <b># other actions</b> are executed when awk is reading the second file, if the condition in <b># other condition</b> is met. The <code>next</code> at the end of the first action block is needed to prevent the condition in <b># other condition</b> from being evaluated, and the actions in <b># other actions</b> from being executed, while awk is reading the first file. <br>\n",
    "A nice visualization of <code>NR==FNR</code> is given [here](https://www.unix.com/shell-programming-and-scripting/197115-nr-fnr-confusions.html).\n",
    "\n",
    "    So <code>NR==FNR</code> means: while the <b>total record number</b> (NR) is equal to the <b>file record number</b> (FNR of file1), do the following commands..<br>\n",
    "    When NR is not equal anymore to FNR this means that we started to read input from file2, which is what we want to avoid. \n",
    "\n",
    "2. <code>a[\\$1]</code> reads in the first field of file1 and indexes it in array <b>a</b> and with <code>=$2</code> assigns the values of the second field of file1 to this index\n",
    "    \n",
    "3. Next, when the condition <code>\\$1 in a</code> is true (when the same value/string is present in field 1 of file2 and in array a): do <code>{print $0,\"\\t\"a[$1]}</code> which prints the whole line of file2 plus a delimiter tab prior to the value assigned to the index in a.\n",
    "\n",
    "In our program this means:\n",
    "* The name of our scaffolds are the first field in <i>metatoy.magnitudes</i> and the magnitudes (second column in this file) are assigned to them.\n",
    "* When the name of the scaffold is also present in the <code>ktClassifyBLAST</code> output file, print the whole line of this second file and append the magnitudes at the end preceded by a delimiter tab. \n",
    "* Store this in a new <i>metatoy.magnitudes.tab</i> file\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
