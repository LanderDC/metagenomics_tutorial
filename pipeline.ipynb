{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"https://rega.kuleuven.be/cev/viralmetagenomics/pictures/lovm/image_preview\" height=\"10%\" width=\"10%\" />\n",
    "\n",
    "# JM-lab bioinformatics pipeline: virome analysis tutorial\n",
    "This jupyter notebook gives an overview of the commands needed for the primary analysis of raw NGS data, flavoured with explanations and neat tips and tricks. This is intended as a learning tool for new PhD-students, master students, interns, etc. Basic command-line knowledge is required to be able to complete this tutorial, a Linux introduction course like [this one](https://ryanstutorials.net/linuxtutorial/) should suffice.\n",
    "\n",
    "This tutorial can be followed by running the commands directly from the terminal or within this jupyter notebook. To run a jupyter notebook on the teaching server, copy it to the `~/data/jupyternotebooks/` folder and open an internet browser to navigate to [bmw.gbiomed.kuleuven.be](https://bmw.gbiomed.kuleuven.be/), log in with your KU Leuven credentials which should finally allow you to run the notebook. You can find more information on how to transfer files to a remote server [below](#1.2-Installing-an-SFTP-client).\n",
    "\n",
    "#### Overview:\n",
    "\n",
    "* [Part 1: Preparation](#Part-1:-Preparation)\n",
    "* [Part 2: Pipeline](#Part-2:-Start-pipeline)\n",
    "    * [Trimming and QC](#2.1-Trimming-and-QC)\n",
    "    * Removing contamination\n",
    "    * Assembly\n",
    "    * Taxonomical annotation\n",
    "    * Krona\n",
    "---\n",
    "## **Part 1: Preparation**\n",
    "### 1.1 Logging into the teaching server\n",
    "To be able to perform analysis on a Linux machine or a server, a connection needs to be made through the shell of the operating system. Through this shell we can use the command-line interface to execute tasks.\n",
    "\n",
    "For this tutorial we can work on the teaching server of gbiomed (bmw.gbiomed.kuleuven.be). Everyone with a u- or r-number from KU Leuven can connect to this remote server by using `ssh` ([more info](https://searchsecurity.techtarget.com/definition/Secure-Shell)) with your KU Leuven credentials.\n",
    "\n",
    "MacOS and Linux users can already proceed to the next step as these operating systems already have a terminal and `ssh` natively installed. \n",
    "\n",
    "Windows users on the other hand, will have to install an SSH client ([PuTTY](https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) or [Bitvise](https://www.bitvise.com/ssh-client-download)) or a Linux subsytem for Windows (the latter is preferred because it is already a part of Windows and subsequently the next steps will be the same as for Linux and Mac users). Instructions on how to install Ubuntu on Windows can be found [here](https://ubuntu.com/tutorials/ubuntu-on-windows#1-overview), be aware that this requires at least a x86 PC running Windows 10 (Fall Creators update Oct 2017).\n",
    "\n",
    "**Perform following actions in a terminal (command-line interface):**\n",
    "\n",
    "<span style=\"color:red\">Replace uXXXXXXX with your u- or r-number. </span>\n",
    "```bash\n",
    "ssh u/rXXXXXXX@bmw.gbiomed.kuleuven.be\n",
    "```\n",
    "\n",
    "Next, you should give your password connected to your KU Leuven account and you're in!\n",
    "\n",
    "<b><span style=\"color:red\"> Important:</span> You will log in to the `home` directory, but always avoid working in here as this has limited storage and will cause trouble when it's full!</b> Therefore, on the teaching server, work in the `data` directory, which is a symbolic link to `/mnt/storage/uXXXXXXX`. Here, you will have enough space to store raw data, results and databases.\n",
    "\n",
    "### 1.2 Installing an SFTP client\n",
    "\n",
    "In order to transfer files from your local computer to a remote server you need an SFTP (SSH or Secure File Transfer Protocol) client, a commonly used SFTP client is [FileZilla](https://filezilla-project.org/). You can download and install it through the FileZilla project website.\n",
    "\n",
    "*Note: Bitvise is an SSH and SFTP client in one, so if you're using Bitvise there is no need to install FileZilla.*\n",
    "\n",
    "Once you installed and opened FileZilla, it should look like this:\n",
    "\n",
    "<img src=\"images/Filezilla_start.png\" height=\"60%\" width=\"60%\" style=\"left\" />\n",
    "\n",
    "On top of the program you can fill out the host (bmw.gbiomed.kuleuven.be), your u/r-number and password connected to KU Leuven and set the port to 22 (see image above). \n",
    "\n",
    "Once you click connect you should be able to transfer files from your computer to the remote server simply by dragging them one or the other way.\n",
    "\n",
    "<img src=\"images/Filezilla_transfer.png\" height=\"60%\" width=\"60%\" style=\"left\" />\n",
    "\n",
    "<span style=\"color:red\"> Important:</span> FileZilla will connect to your `home` directory by default, but do not copy files here! Instead, copy them to the `data` directory.\n",
    "\n",
    "#### 1.2.1 Transfer files\n",
    "Make a new directory in your data folder and transfer all provided files (FASTQ, database, primer file, etc.) to this directory with FileZilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ~/data/meta_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Installing all necessary software on the remote server\n",
    "#### 1.3.1 Miniconda\n",
    "(Mini)conda is a package manager from which you can install a lot of (bioinformatics) software. More info on conda can be found [here](https://docs.conda.io/projects/conda/en/latest/).\n",
    "\n",
    "**Perform following steps to install all software we will need along the pipeline:**\n",
    "1. Create in your datafolder a new `software` directory and move into that directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: cd: /Users/lander/data: No such file or directory\n",
      "/Users/lander/Documenten/Doctoraat/Metagenomic tutorial/software\n"
     ]
    }
   ],
   "source": [
    "cd ~/data\n",
    "mkdir software\n",
    "cd software\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the Miniconda installer with `wget`. Next, run the installation script (`-b` makes the installation run silent and `-p` provides the path where to install Miniconda). When Miniconda is installed, activate conda by sourcing the initialization script, this simply sets a couple of shell environment variables, and `conda` command as a shell function. More information in the [installer guidelines](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: wget: command not found\n",
      "bash: Miniconda3-latest-Linux-x86_64.sh: No such file or directory\n",
      "bash: /Users/lander/data/software/miniconda/bin/activate: No such file or directory\n",
      "no change     /Users/lander/.miniconda/miniconda3/condabin/conda\n",
      "no change     /Users/lander/.miniconda/miniconda3/bin/conda\n",
      "no change     /Users/lander/.miniconda/miniconda3/bin/conda-env\n",
      "no change     /Users/lander/.miniconda/miniconda3/bin/activate\n",
      "no change     /Users/lander/.miniconda/miniconda3/bin/deactivate\n",
      "no change     /Users/lander/.miniconda/miniconda3/etc/profile.d/conda.sh\n",
      "no change     /Users/lander/.miniconda/miniconda3/etc/fish/conf.d/conda.fish\n",
      "no change     /Users/lander/.miniconda/miniconda3/shell/condabin/Conda.psm1\n",
      "modified      /Users/lander/.miniconda/miniconda3/shell/condabin/conda-hook.ps1\n",
      "no change     /Users/lander/.miniconda/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh\n",
      "no change     /Users/lander/.miniconda/miniconda3/etc/profile.d/conda.csh\n",
      "no change     /Users/lander/.bash_profile\n",
      "\n",
      "==> For changes to take effect, close and re-open your current shell. <==\n",
      "\n",
      "bash: /Users/lander/.bashrc: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/data/software/miniconda\n",
    "source $HOME/data/software/miniconda/bin/activate\n",
    "conda init\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that* `$HOME` *and* `~/` *both point to your `home` directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. When installing new software with conda, the best practice is to create a new conda environment for each project you are working on, for example:\n",
    "\n",
    "In this tutorial we will run the virome pipeline, so we will create a conda environment with all software we need to run the pipeline installed in this environment. Then we need to activate this environment to make the software available for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -y --name virome_pipeline python\n",
    "conda activate virome_pipeline\n",
    "conda install -y -c bioconda -c anaconda krona samtools bwa-mem2 bowtie2 trimmomatic bedtools fastqc pigz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading taxonomy database for Krona\n",
    "Krona is installed but we still need to run `ktUpdateTaxonomy.sh` to download the taxonomy database, see message below:\n",
    "\n",
    "```console\n",
    "Krona installed.  You still need to manually update the taxonomy databases before Krona can generate taxonomic reports. The update script is ktUpdateTaxonomy.sh. \n",
    "The default location for storing taxonomic databases is /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "\n",
    "If you would like the taxonomic data stored elsewhere, simply replace\n",
    "this directory with a symlink.  For example:\n",
    "```\n",
    "```bash\n",
    "rm -rf /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "mkdir /path/on/big/disk/taxonomy\n",
    "ln -s /path/on/big/disk/taxonomy /home/luna.kuleuven.be/u0140985/data/software/miniconda/envs/virome_pipeline/opt/krona/taxonomy\n",
    "ktUpdateTaxonomy.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktUpdateTaxonomy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 From another source\n",
    "\n",
    "The bioconda installation will most of the time lag a few versions behind the most current release. If you really want the most recent, then you'll need to manually install the software and its dependencies.\n",
    "\n",
    "Next to Anaconda/Miniconda their are a lot of other possibilities to install software (`pip`, compiling from source, unpacking binaries, installing from github repository, etc.)\n",
    "\n",
    "As the latest version of [Diamond](https://github.com/bbuchfink/diamond) (a sequence aligner for protein and translated DNA searches) is not available through `conda`, we can install it from github by following the [installation instructions](https://github.com/bbuchfink/diamond/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd ~/data/software/\n",
    "mkdir diamond\n",
    "cd diamond\n",
    "wget http://github.com/bbuchfink/diamond/releases/download/v2.0.6/diamond-linux64.tar.gz\n",
    "tar -xzf diamond-linux64.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still need to put the diamond executable in our `PATH` variable so we can call the `diamond` command from everywhere in the command line. This can be done by making a `bin` subdirectory in `~/data/software/`, followed by creating a symlink from the `diamond` executable to `~/data/software/bin/` and finally export this directory to our `$PATH` by adding it to your `.profile` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/data/software\n",
    "mkdir bin\n",
    "cd bin/\n",
    "ln -s ~/data/software/diamond/diamond ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, open the `.profile` file with `nano` (a text editor) and add following line to the bottom of the file:\n",
    "```bash\n",
    "PATH=\"~/data/software/bin:$PATH\"\n",
    "```\n",
    "More documentation on where and how to set the `PATH` variable in these two topics: \n",
    "* https://superuser.com/questions/183870/difference-between-bashrc-and-bash-profile/183980#183980 \n",
    "* https://unix.stackexchange.com/questions/26047/how-to-correctly-add-a-path-to-path\n",
    "\n",
    "\n",
    "When you `source` your `.profile` file, you should now be able to call `diamond`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ~/.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the version of Diamond you have installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diamond version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Exercise\n",
    "Try to install the latest version of [SPAdes](https://github.com/ablab/spades) by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Part 2: Start pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we start, some tips:**\n",
    "1. Always make sure you're working in the right directory (`pwd`)\n",
    "2. <kbd>Ctrl</kbd> + <kbd>C</kbd> kills tasks, useful when they get stuck\n",
    "3. `#` in a shell script, code block,... will allow you to leave comments in your code, as all lines with a '#' in front will not be interpreted\n",
    "4. Undoubtedly errors will occur, read them carefully and try to understand what they are trying to tell you\n",
    "5. Google is your friend! Websites like Stackoverflow, Superuser, Biostars, etc. most likely contain the answers to your questions (if you can phrase them properly)\n",
    "\n",
    "### 2.1 Trimming and QC\n",
    "**Raw reads are imperfect** due to presence of primer and adapter sequences from WTA2, Nextera library prep,... and because NGS inherently produces some errors during base calling. The quality of such a base call gets encoded in a FASTQ file as a [PHRED-score](https://en.wikipedia.org/wiki/Phred_quality_score#:~:text=The%20FASTQ%20format%20encodes%20phred,efficacy%20of%20different%20sequencing%20methods.). This also means that the raw reads have to be filtered and trimmed for these imperfections. We can do this by using software (eg. Trimmomatic) that will trim the reads based on base call quality and the presence of adapter sequences, provided in a fasta file by the user. However, also after trimming your reads it is best to check the quality of you samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Trimmomatic\n",
    "We start by trimming the reads in our sample with Trimmomatic, a flexible read trimming tool for Illumina NGS data.\n",
    "\n",
    "The current Trimmomatic trimming steps are:\n",
    "\n",
    "- **ILLUMINACLIP**: Cut adapter and other illumina-specific sequences from the read. You can provide a file with all sequences to cut (for this tutorial we use *primer_WTA2_Nextera.fa*).\n",
    "- **SLIDINGWINDOW**: Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold.\n",
    "- **LEADING**: Cut bases off the start of a read, if below a threshold quality\n",
    "- **TRAILING**: Cut bases off the end of a read, if below a threshold quality\n",
    "- **CROP**: Cut the read to a specified length *(not used in our pipeline)*\n",
    "- **HEADCROP**: Cut the specified number of bases from the start of the read\n",
    "- **MINLEN**: Drop the read if it is below a specified length\n",
    "\n",
    "It works with FASTQ, either uncompressed or gzipp'ed FASTQ. Use of gzip format is determined based on the .gz extension.\n",
    "\n",
    "For single-ended data, one input and one output file are specified, plus the processing steps. For paired-end data, two input files are specified, and 4 output files, 2 for the 'paired' output where both reads survived the processing, and 2 for corresponding 'unpaired' output where a read survived, but the partner read did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to the directory where you stored the tutorial files\n",
    "cd ~/data/meta_tutorial\n",
    "pwd #make sure you're in the right directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make new folders where you will store the data for each individual sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir sample1\n",
    "cd sample1\n",
    "mkdir READ\n",
    "mv ../sample1.R* ./READ\n",
    "cd ./READ\n",
    "mkdir TRIMMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After unzipping the FASTQ files, start Trimmomatic:\n",
    "\n",
    "*Try to understand what all specified options do in the Trimmomatic command*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd #your working directory should be ~/data/meta_tutorial/sample1/READ/ if you used the same names as in this notebook\n",
    "\n",
    "pigz -d -p 20 -c sample1.R1.fastq.gz > sample1.R1.fastq\n",
    "pigz -d -p 20 -c sample1.R2.fastq.gz > sample1.R2.fastq\n",
    "\n",
    "#PE stands for Paired-end, for single-end reads use SE\n",
    "trimmomatic PE -threads 20 sample1.R1.fastq sample1.R2.fastq \\ #the backslash (\\) allows us to let the command continue over multiple lines\n",
    "                TRIMMED/sample1.R1.trimmed.fastq TRIMMED/sample1.R1.unpaired.fastq TRIMMED/sample1.R2.trimmed.fastq \\\n",
    "                TRIMMED/sample1.R2.unpaired.fastq \\\n",
    "                ILLUMINACLIP:~/data/meta_tutorial/primer_WTA2_Nextera.fa:2:30:10:1:true \\\n",
    "                HEADCROP:19 LEADING:15 TRAILING:15 SLIDINGWINDOW:4:20 MINLEN:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Concatenate the unpaired reads and in order to save storage space, remove all intermediary files and gzip the trimmed fastq files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat TRIMMED/sample1.R1.unpaired.fastq TRIMMED/sample1.R2.unpaired.fastq > TRIMMED/sample1.unpaired.fastq\n",
    "rm TRIMMED/sample1.R1.unpaired.fastq\n",
    "rm TRIMMED/sample1.R2.unpaired.fastq\n",
    "cd TRIMMED\n",
    "\n",
    "pigz -p 20 -c -9 sample1.R1.trimmed.fastq > sample1.R1.trimmed.fastq.gz\n",
    "pigz -p 20 -c -9 sample1.R2.trimmed.fastq > sample1.R2.trimmed.fastq.gz\n",
    "pigz -p 20 -c -9 sample1.unpaired.fastq > sample1.unpaired.trimmed.fastq.gz\n",
    "\n",
    "rm sample1.R1.trimmed.fastq\n",
    "rm sample1.R2.trimmed.fastq\n",
    "rm sample1.unpaired.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 FastQC\n",
    "Most sequencers will generate a QC report as part of their analysis pipeline, but this is usually only focused on identifying problems which were generated by the sequencer itself. FastQC aims to provide a QC report which can spot problems which originate either in the sequencer or in the starting library material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
